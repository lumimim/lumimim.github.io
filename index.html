<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title> Lu Mi </title>
  
  <meta name="author" content="Lu Mi">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/head_icon_lm.jpg">
</head>

<body>
  <table style="width:140%;max-width:940px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:85%;vertical-align:middle">
              <p style="text-align:center">
                <name>Lu Mi &nbsp 米璐</name>
              </p>
              <p> 
                I am currently a <a href="https://alleninstitute.org/what-we-do/brain-science/careers/shanahan-foundation-fellowship/">Shanahan Foundation Fellow</a> at the <a href="https://alleninstitute.org/">Allen Institute</a>,
                and postdoctoral researcher at the <a href="https://www.washington.edu/">University of Washington, Seattle</a>.
                Prior to that, I received my Ph.D. at <a href="https://www.csail.mit.edu/">MIT CSAIL</a> in 2022,
                where I studied in <a href="http://ccg.csail.mit.edu/">Computational Connectomics Group</a>. 
                I was fortunate to be advised by Prof. <a href="https://people.csail.mit.edu/shanir/">Nir Shavit</a> at MIT,
                and co-advised by Prof. <a href="https://scholar.harvard.edu/aravisamuel/home/">Aravinthan D.T. Samuel</a> 
                and Prof. <a href="https://lichtmanlab.fas.harvard.edu/people/jeff-lichtman/">Jeff W. Lichtman</a> at <a href="http://cbs.fas.harvard.edu/">Harvard Center for Brain Science</a>.
                I also did research at <a href="https://research.google/teams/">Google</a>, <a href="https://waymo.com/">Waymo</a> and <a href="https://www.janelia.org/">HHMI Janelia Research Campus</a>. 
              </p>
              <p>
                I received my M.S. degree at <a href="https://www.eecs.mit.edu/">MIT EECS</a> in 2019, and B.S. degree at <a href="https://www.tsinghua.edu.cn/en/">Tsinghua</a> in 2017.
              </p>
              <p style="text-align:center">
                <a href="mailto:milu@uw.edu">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=vokCG-MAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/Lumi871">Twitter</a>  &nbsp/&nbsp
                <a href="https://drive.google.com/file/d/1cBZglQCdko-GAD-yyBTMn61RazWEezQ2/view?usp=share_link">CV</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/Lu_Mi.jpg"><img style="width:180%;max-width:180%" alt="profile photo" src="images/Lu_Mi.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>  
          <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
        My research interest is NeuroAI, which studies the intersection of natural intelligence and artificial intelligence. During my PhD, I developed advanced deep learning tools for fast and scalable automatic connectomics pipelines to discover the brain, and linking the anatomical structure and neural activity with whole-brain modeling.
        In the current collaboration with investigators at the Allen Institute and the University of Washington, I am developing interpretable deep learning approaches including probabilistic modeling and representation learning for biological and artificial systems. My research topics broadly include
        <br>(1) Developing fast and scalable automatic pipelines to discover the brain;<br> (2) Modeling brain with multi-modal neural data; <br> (3) Understanding the robustness and efficiency of coding, computation and learning in biological and artificial systems; <br> (4) Building brain-inspired AI frameworks.
        </p>
        <p>
        <br>
        <em>
        I'm looking for motivated Ph.D. collaborators who are passionate about NeuroAI. Drop me an <a href="mailto:lu.mi@alleninstitute.org">email</a> if you are interested! </em>
              </p>
            </td>
          </tr>

        
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
                <ul>
                  <li>[02/23] I gave a guest lecture on <a href = "https://drive.google.com/file/d/1CzIvGe_9nHYphJBmfdUiXaTVkKRcZrjU/view?usp=share_link">Biophysics VAEs</a> in Deep Learning for Neuroscience course (CSE 599N) at University of Washington, Seattle.<br>
                  <li>[01/23] Our work on <a href = "http://128.84.21.203/pdf/2303.00882">Xray2EM: Cross-Modality Image Reconstruction</a> was accepted at ISBI 2023.<br>
                  <li>[11/22] Our organized challenge on <a href="https://xpress.grand-challenge.org/">Xray Projectomic Reconstruction</a> was accepted at ISBI 2023.<br>
                  <li>[09/22] I gave a short talk on <a href = "https://drive.google.com/file/d/1uyG1vSUR4LaKPD-Qy-29Q77mfQUblldv/view?usp=sharing">How to Link Multi-Modal Neural Data with Deep Learning</a> at NeuroAI in Seattle 2022. <br>
                  <li>[09/22] I joined Allen Institute as <a href="https://alleninstitute.org/what-we-do/brain-science/careers/shanahan-foundation-fellowship/">Shanahan Foundation Fellow</a>, and University of Washington, Seattle as postdoctoral researcher.
                  <li>[08/22] Ph.D. <a href="https://drive.google.com/file/d/1dLeZ7ipYY_jeT_WWU1sJtTn-H3Jw_zi4/view?usp=share_link">Thesis</a> defended!
                  <li>[08/22] I received the <a href="https://alleninstitute.org/what-we-do/brain-science/careers/shanahan-foundation-fellowship/"> 2022 Shanahan Foundation Fellowship</a>. <br>
                  <li>[08/22] I was selected into <a href="https://risingstars.utexas.edu/"> 2022 Rising Stars in EECS</a>.<br>
                  <li>[04/22] I gave a talk on <a href = "https://drive.google.com/file/d/1T0jX3Q8Sst9ecjF2zisIVpcu-g0MuA2D/view?usp=share_link">Deep Learning Tools for Next-Generation Connectomics</a> at Allen Institute.<br>
                  <li>[01/22] Our work on <a href ="https://openreview.net/pdf?id=CJzi3dRlJE-">Connectome-Constrained Modeling</a> was accepted at ICLR 2022.<br>
                  <li>[01/22] I gave a talk on <a href = "https://drive.google.com/file/d/1bVQjfR2OOiFDQgoR2qjUDyA7z3a8IqPH/view?usp=sharing">Connectome-Constrained Modeling</a> in Computational Neuroscience Seminar at Flatrion Institute.<br>
                  <li>[12/21] Our work on <a href="https://arxiv.org/pdf/1910.04858.pdf">Training-Free Uncertainty Estimation</a> was accepted at AAAI 2022.<br>
                  <li>[06/21] I joined Google Research as a research intern.<br>
                  <li>[06/21] I received the <a href="https://science.mit.edu/resource/mathworks-fellowship/">2021 MathWorks Fellowship</a>.<br>
                  <li>[02/21] Our work on <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Mi_HDMapGen_A_Hierarchical_Graph_Generative_Model_of_High_Definition_Maps_CVPR_2021_paper.pdf">HD Maps Generation</a> was accepted at CVPR 2021.<br>
                  <li>[01/21] Our work on <a href="https://drive.google.com/file/d/1IH7eefLLfB6ihwZjdHV_U1lVhcBjg-VV/view?usp=sharing">Connectome-Constrained Modeling</a> was accepted at Cosyne 2021. <br>
                  <li>[09/20] I received the <a href="https://www.miccai2020.org/en/MICCAI-2020-NIH-AWARDS.html">NIH Awards</a> at MICCAI 2020.<br>
              </ul>
            </td>
          </tr>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Selected Publications</heading>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td > &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; * indicates equal contribution </td>
        </tr>

        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Representative papers are <span class="highlight">highlighted</span>.

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/xray2em.png' width="190">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://128.84.21.203/pdf/2303.00882">
                <papertitle>X-Ray2EM: Uncertainty-Aware Cross-Modality Image Reconstruction from X-Ray to Electron Microscopy in Connectomics</papertitle>
              </a>
              <br>
              Yicong Li, Yaron Meirovitch, Aaron T. Kuan, Jasper S. Phelps, Alexandra Pacureanu, Wei-Chung Allen Lee, Nir Shavit, <strong>Lu Mi</strong>
              <br>
              <em> 
              IEEE - ISBI 2023
              </em>
              <br>
              <p></p>
              <p>
                We propose an uncertainty-aware 3D reconstruction model that translates X-Ray images to EM-like images with enhanced membrane segmentation quality.
              </p>
              <p>
                <a href="http://128.84.21.203/pdf/2303.00882">arxiv</a>
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/xpress.png' width="190">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2302.03819.pdf">
                <papertitle>The XPRESS challenge: Xray Projectomic Reconstruction - Extracting Segmentation with Skeletons</papertitle>
              </a>
              <br>
              Tri Nguyen, Mukul Narwani, Mark Larson, Yicong Li, Shuhan Xie, Hanspeter Pfister, Donglai Wei, Nir Shavit, <strong>Lu Mi</strong>, Alexandra Pacureanu, Wei-Chung Lee, Aaron T. Kuan
              <br>
              <em> 
                IEEE - ISBI Challenge 2023
              </em>
              <br>
              <p></p>
              <p>
                We organize an instance segmentation challenge with volumetric XNH images of cortical white matter axons from the mouse brain at 100 nm per voxel isotropic resolution. Both skeleton and voxel ground truth annotations are provided for axon trajectories. 
              </p>
              <p></p>
              <p>
                <a href="https://xpress.grand-challenge.org">link</a>
                / <a href="https://arxiv.org/pdf/2302.03819.pdf">arxiv</a>
                / <a href="https://github.com/trivoldus28/xray-challenge-eval">code</a>
                / <a href="https://colab.research.google.com/drive/1exhXGyXv30GIsIv-QhSA9LiWmZd4c7FS?usp=sharing">tutorial</a>
                </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/im2nerf.png' width="190">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2209.04061.pdf">
                <papertitle>im2nerf: Image to Neural Radiance Field in the Wild</papertitle>
              </a>
              <br>
              <strong>Lu Mi</strong>, Abhijit Kundu, David Ross, Frank Dellaert, Noah Snavely,  Alireza Fathi
              <br>
              <p></p>
              <p>
                We propose im2nerf, a learning framework with deep generative model that predicts a continuous neural object representation given a single input image in the wild, supervised by only segmentation output from off-the-shelf recognition methods.
              </p>
              <p></p>
              <p>
                <a href="https://arxiv.org/pdf/2209.04061.pdf">arxiv</a>
                </p>
            </td>
          </tr>


          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/iclr_vae_worm.png' width="190">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openreview.net/pdf?id=CJzi3dRlJE-">
                <papertitle>Connectome-constrained Latent Variable Model of Whole-Brain Neural Activity</papertitle>
              </a>
              <br>
              <strong>Lu Mi</strong>, Richard Xu, Sridhama Prakhya, Albert Lin, Nir Shavit, Aravinthan D.T. Samuel, Srinivas C. Turaga
              <br>
              <em> 
              ICLR 2022
              </em>
              <br>
              <p></p>
              <p>
                We use stochastic threshold linear dynamics to model the whole-brain neural network, using connectome constraint on the neural activity.
              </p>
              <p></p>
              <p>
                <a href="https://openreview.net/pdf?id=CJzi3dRlJE-">pdf</a>
                / <a href="https://github.com/TuragaLab/wormvae">code</a>
                </p>
            </td>
          </tr>



          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/uncertainty.png' width="190">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/1910.04858.pdf">
                <papertitle>Training-Free Uncertainty Estimation for Dense Regression: Sensitivity as a Surrogate</papertitle>
              </a>
              <br>
              <strong>Lu Mi</strong>, Hao Wang, Yonglong Tian, Hao He, Nir Shavit
              <br>
              <em> 
              AAAI 2022 <br>
              ICML 2021 Workshop on Uncertainty & Robustness in Deep Learning</em>
              <br>
              <p></p>
              <p>
                We perform a systematic exploration into training-free uncertainty estimation for dense regression, an unrecognized yet important problem, and provide a theoretical construction justifying such estimations.
              </p>
              <p></p>
              <p>
              <a href="https://arxiv.org/pdf/1910.04858.pdf">arxiv</a>
              / <a href="https://aaai-2022.virtualchair.net/poster_aaai6130">video</a>
              / <a href="https://docs.google.com/presentation/d/1GRjohCl03sw1Hjr0i5uIxdU8wDSro-Bv/edit?usp=sharing&ouid=115002766269276500672&rtpof=true&sd=true">slides</a>
              / <a href="https://drive.google.com/file/d/13Jbe_c9UuMCe-RrOQ_0RjegHI2KJwXeP/view?usp=sharing">poster</a>
              </p>
            </td>
          </tr> 

         <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/roadgraph.png' width="180">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Mi_HDMapGen_A_Hierarchical_Graph_Generative_Model_of_High_Definition_Maps_CVPR_2021_paper.pdf">
                <papertitle>HDMapGen: A Hierarchical Graph Generative Model of High Definition Maps</papertitle>
              </a>
              <br>
              <strong>Lu Mi</strong>, Hang Zhao, Charlie Nash, Xiaohan Jin, Jiyang Gao, Chen Sun, Cordelia Schmid, Nir Shavit, Yuning Chai, Dragomir Anguelov
              <br>
							<em>CVPR 2021</em>
              <br>
              <p></p>
              <p>
              We propose HDMapGen, a hierarchical graph generative model capable of producing high-quality and diverse HD maps.
              </p>
              <p>
                <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Mi_HDMapGen_A_Hierarchical_Graph_Generative_Model_of_High_Definition_Maps_CVPR_2021_paper.pdf">pdf</a>
                 / <a href="https://drive.google.com/file/d/1bmMkEFAWQnRK-UqHO2DmHDKPKz7dPLHO/view?usp=sharing">video</a> 
                 / <a href="https://drive.google.com/file/d/1F1gZ7lOMw7uPqjOt-gl0DT5JgPb5qpTV/view?usp=sharing">slides</a>
                 / <a href="https://drive.google.com/file/d/1l0qdkOsFSgqn9CptzFFaSRdq9ynOe-v-/view?usp=sharing">poster</a>
                </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/worm_vae.png' width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1IH7eefLLfB6ihwZjdHV_U1lVhcBjg-VV/view?usp=sharing">
                <papertitle>Connectome-constrained Latent Variable Model of C. elegans Chemosensation</papertitle>
              </a>
              <br>
              <strong>Lu Mi</strong>, Richard Xu, Sridhama Prakhya, Albert Lin, Aravinthan D.T. Samuel, Srinivas C. Turaga
              <br>
              <em> 
              Cosyne 2021
              </em>
              <br>
              <p></p>
              <p>
                We use stochastic threshold linear dynamics to model the C. elegans neural network, using connectome constraint on the neural activity.
              </p>
              <p></p>
              <p>
                <a href="https://drive.google.com/file/d/1IH7eefLLfB6ihwZjdHV_U1lVhcBjg-VV/view?usp=sharing">pdf</a>
                 / <a href="https://docs.google.com/presentation/d/e/2PACX-1vSYjGofhuY9Ui_6PxRQRYGVc_Bai2XZU7szL6U2uEtfKrtvPet9ovyvJmN-Txx925guRq5udaiL1MVV/pub?start=false&loop=false&delayms=3000">slides</a>
                 / <a href="https://drive.google.com/file/d/1xkitmxASx6zSzoj5O73P6rmUA_8z-q_5/view?usp=sharing">poster</a>
                </p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/microscope.png' width="180">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2101.02746.pdf">
                <papertitle>Learning Guided Electron Microscopy with Active Acquisition</papertitle>
              </a>
              <br>
              <strong>Lu Mi</strong>, Hao Wang, Yaron Meirovitch, Richard Schalek, Srinivas C. Turaga, Jeff W. Lichtman, Aravinthan D. T. Samuel, Nir Shavit
              <br>
							<em>MICCAI 2020</em>
              <br>
              <p></p>
              <p>
                We show how to use deep learning to accelerate and optimize single-beam SEM acquisition of images.
              </p>
              <p>
                <a href="https://arxiv.org/pdf/2101.02746.pdf">arxiv</a>
                 / <a href="https://github.com/lumi9587/learning-guided-SEM">code</a>
                </p>
            </td>
          </tr> 


          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/3c.png' width="180">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Meirovitch_Cross-Classification_Clustering_An_Efficient_Multi-Object_Tracking_Technique_for_3-D_Instance_CVPR_2019_paper.pdf">
                <papertitle>Cross-Classification Clustering: An Efficient Multi-Object Tracking Technique for 3-D Instance Segmentation in Connectomics</papertitle>
              </a>
              <br>
              Yaron Meirovitch*, <strong>Lu Mi</strong>*, Hayk Saribekyan, Alexander Matveev, David Rolnick, Nir Shavit
              <br>
							<em>CVPR 2019</em>
              <br>
              <p></p>
              <p>
                We introduce cross-classification clustering (3C), a technique that simultaneously tracks complex, interrelated objects in an image stack.
              </p>
              <p>
                <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Meirovitch_Cross-Classification_Clustering_An_Efficient_Multi-Object_Tracking_Technique_for_3-D_Instance_CVPR_2019_paper.pdf">pdf</a>
                </p>
            </td>
          </tr> 


           <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/vae_gan_collapse.png' width="180">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/1812.05676.pdf">
                <papertitle>A Probe Towards Understanding GAN and VAE Models</papertitle>
              </a>
              <br>
              <strong>Lu Mi</strong>*, Macheng Shen*, Jingzhao Zhang*
              <br>
              <p></p>
              <p>
                We summarize our experiment results that compare these two categories of models GAN and VAE in terms of fidelity and mode collapse.
              </p>
              <p>
                <a href="https://arxiv.org/pdf/1812.05676.pdf">arxiv</a>
                </p>
            </td>
          </tr>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Professional Services</heading>
                <ul>
                  <li>Reviewer for CVPR, ECCV, ICCV, AAAI.<br>
                  <li>Guest lecture on Biophysics VAEs, Deep Learning for Neuroscience, CSE 599N, University of Washington, Seattle, 2023.<br>
                  <li>Talk on How to Link Multi-Modal Neural Data with Deep Learning, NeuroAI in Seattle, 2022.<br>
                  <li>Talk on Deep Learning Tools for Next-Generation Connectomics, Allen Institute, 2022.<br>
                  <li>Talk on Connectome-Constrained Modeling, Computational Neuroscience Seminar, Flatrion Institute, 2022.<br>
                  <li>Talk on Connectome-Constrained Modeling, CVML meeting, HHMI Janelia Research Campus, 2021.<br>
                  <li>Talk on Cross-Classification Clustering Segmentation, Machine Learning & Biology NSF Workshop, 2019.<br>
                  <li>TA for MIT 6.555 (Biomedical Signal and Image Processing) by Julie Greenberg, 2019.<br>
              </ul>
            </td>
          </tr>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research Experience</heading>
                <ul>
                  <li>2022.9 - present, Shanahan Foundation Fellow & Postdoctoral Researcher, Allen Institute & University of Washington<br>
                  <li>2017.8 - 2022.8, Research Assistant, MIT Computer Science and Artificial Intelligence Laboratory<br>
                    Advisor: Prof. <a href="https://people.csail.mit.edu/shanir/">Nir Shavit</a><br>
                  <li>2020.3 - 2022.8, Fellow, Harvard Center for Brain Science<br>
                    Advisors: Prof. <a href="https://scholar.harvard.edu/aravisamuel/home/">Aravinthan D.T. Samuel</a>, Prof. <a href="https://lichtmanlab.fas.harvard.edu/people/jeff-lichtman/">Jeff W. Lichtman</a>
                  <li>2021.6 - 2021.12, Research Intern, Google Research Team<br>
                    Advisors: Dr. <a href="https://www.alirezafathi.org/">Alireza Fathi</a>, Prof. <a href="https://www.cs.cornell.edu/~snavely/">Noah Snavely</a>, Dr. <a href="https://abhijitkundu.info/">Abhijit Kundu</a>, Prof. <a href="https://dellaert.github.io/">Frank Dellaert</a><br>
                  <li>2020.3 - 2021.11, Visiting Student, HHMI Janelia Research Campus<br>
                    Advisor: Dr. <a href="https://www.janelia.org/people/srinivas-turaga">Srinivas C. Turaga</a>
                  <li>2020.6 - 2020.8, Research Intern, Waymo Research Team<br>
                    Advisors: Prof. <a href="https://hangzhaomit.github.io/">Hang Zhao</a>, Dr. <a href="https://charlienash.github.io/">Charlie Nash</a>, Dr. <a href="https://jiyanggao.github.io/">Jiyang Gao</a>, Prof. <a href="https://chensun.me/">Chen Sun</a><br>
              </ul>
            </td>
          </tr>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Education</heading>
                <ul>
                  <li>2017.8 - 2022.8, Massachusetts Institute of Technology<br>
			  Doctor of Philosophy in Computer Science<br>Minor in Computational Neuroscience<br>
                  <li>2017.9 - 2019.6, Massachusetts Institute of Technology<br>
                    Master of Science in Electrical Engineering and Computer Science <br>
                  <li>2013.9 - 2017.6, Tsinghua University<br>
                      Bachelor of Science in Measurement, Control and Instruments <br>
              </ul>
            </td>
          </tr>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Honors and Awards</heading>
                <ul>
                  <li>Shanahan Foundation Fellowship, Allen Institute & University of Washington, Seattle, 2022<br>
                  <li>Risng Stars in EECS, UT Austin, 2022<br>
                  <li>MathWorks Fellowship, MIT EECS, 2021<br>
                  <li>NIH Awards, MICCAI, 2020<br>
                  <li>Grass Instruments Co. Fellowship, MIT EECS, 2017<br>
                  <li>Tang Lixing Fellowship, Tsinghua (30 in 3000), 2017<br>
                  <li>Best Paper Awards, Optofluidics, 2016<br>
                  <li>1st Prize (Meritorious Winner) COMAP's Mathematical Contest in Modeling (MCM), 2016<br>
              </ul>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                 The design and code of this website is adapted from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron's site</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
